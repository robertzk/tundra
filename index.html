<!DOCTYPE html>
<html lang="en" class="">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta name="description" content="Tundra provides a standardized container format for classifiers developed in R. This allows easier deployment by keeping both the data preparation procedure and the statistics in one place with an easy interface.">

    <title>Standardized container format for deployment of classifiers.</title>

    <link rel="stylesheet" media="all" href="stylesheets/rocco.css" />
    <link rel="stylesheet" media="all" href="stylesheets/github-markdown.css" />

    <script src="assets/highlight.pack.js"></script>
    <script type="text/javascript">
      hljs.initHighlightingOnLoad();
    </script>

    <style type="text/css">
      .header {
        position: fixed;
        top: 0px;
        width: 100%;
        background-color: rgba(0, 0, 0, 0.25);
        padding: 10px;
      }
      
      .header a {
        padding-right: 30px;
      }

      .container {
        margin-top: 40px;
      }

      body {
        padding: 0;
        margin: 0;
      }

      div.code-background {
        float: right;
        position: fixed;
        z-index: -1;
        height: 100%;
        background-color: #f8f8ff;
        width: 60%;
        right: 0px;
      }

      div.section {
        clear: both;
        margin: 0; padding: 0;
      }

      div.code {
        float: right;
        width: 60%;
      }

      code.R {
        font-size: 1.2em;
        line-height: 2em;
        margin-top: 0em;
        margin-bottom: -2em;
        padding-top: 0;
        margin-top: -1em;
      }

      code.R > span.spacer {
        position: relative;
      }

      div.code > pre {
        margin: 0;
        padding-left: 2em;
        margin-top: 0;
        margin-bottom: 0;
      }

      div.markdown {
        padding: 1em;
        padding-top: 0;
        background: #fff;
        float: left;
        width: 35%;
      }
    </style>

  </head>

  <body>
    <div class="header">
      <a href="https://github.com/robertzk/rocco">
        <img id="rocco-logo" src="https://img.shields.io/badge/Generated by rocco_v0.2.1.2-%E2%9C%93-blue.svg"/>
      </a>
    </div>
    <div class="container">

      <div class="code-background"></div>

        <div class="section">
          <div class="markdown markdown-body">
            <h1>tundra_container.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' @name tundra_container
#' @title tundra_container
#' @export
NULL

#' Tundra container class
#'
#' TODO: Formally define parameter spaces for models
#' 
#' @docType class
#' @name tundraContainer
#' @aliases NULL
#' @export
tundra_container <- setRefClass('tundraContainer',  #define reference classes to access by reference instead of by value
  fields = list(keyword = 'character',
                train_fn = 'function',
                predict_fn = 'function',
                munge_procedure = 'ANY',  # tundra contains munge_procedure so that it remembers the data-prep steps
                default_args = 'list',
                trained = 'logical',
                input = 'list',
                output = 'ANY',    # output stores the actual output of the train function (e.g. the model object)
                internal = 'list', # for storing info about the model
                hooks = 'list'),
  methods = list(
    initialize = function(keyword = character(0),
                          train_fn = identity, predict_fn = identity,
                          munge_procedure = list(),
                          default_args = list(),
                          internal = list()) {
      if (!(is.list(munge_procedure) || is(munge_procedure, "stageRunner"))) {
        stop("munge_procedure must be a list or stageRunner", call. = FALSE)
      }
      keyword <<- keyword
      train_fn <<- train_fn
      predict_fn <<- predict_fn
      munge_procedure <<- munge_procedure
      default_args <<- default_args
      internal <<- internal
      trained <<- FALSE
    },

    train = function(dataframe, train_args = list(), verbose = FALSE, munge = TRUE) {
      if (trained)
        stop("Tundra model '", keyword, "' has already been trained.")

      force(train_args); force(verbose); force(munge) 

      .run_hooks('train_pre_munge')

      if (length(munge_procedure) > 0 && identical(munge, TRUE)) {
        require(mungebits)
        triggers <- unlist(lapply(munge_procedure,
                              function(x) inherits(x, 'trigger')))
        
        (if (!verbose) capture.output else function(...) eval.parent(...))(
          dataframe <- mungebits::munge(dataframe, munge_procedure)) # Apply munge_procedure to dataframe

        # Store trained munge_procedure
        munge_procedure <<- attr(dataframe, 'mungepieces')[!triggers]

        # reset mungepieces to NULL after training
        attr(dataframe, 'mungepieces') <- NULL
      }

      run_env <- new.env(parent = old_env <- environment(train_fn))
      on.exit(environment(train_fn) <<- old_env)
      input <<- append(train_args, default_args)
      run_env$input <- input; run_env$output <- output
      debug_flag <- isdebugged(train_fn)
      environment(train_fn) <<- run_env
      if (debug_flag) debug(train_fn)

      .run_hooks('train_post_munge')

      (if (!verbose) capture.output else function(...) eval.parent(...))(
        res <- train_fn(dataframe))           # Apply train function to dataframe

      input <<- run_env$input; output <<- run_env$output
      trained <<- TRUE
      res 
    },

    predict = function(dataframe, predict_args = list(), verbose = FALSE, munge = TRUE) {
      if (!trained)
        stop("Tundra model '", keyword, "' has not been trained yet.")

      force(verbose); force(munge); force(predict_args)

      .run_hooks('predict_pre_munge')

      if (length(munge_procedure) > 0 && identical(munge, TRUE)) {
        require(mungebits)
        initial_nrow <- nrow(dataframe)
        (if (!verbose) capture.output else function(...) eval.parent(...))(
          dataframe <- mungebits::munge(dataframe, munge_procedure)) # Apply munge_procedure to dataframe
        if (nrow(dataframe) != initial_nrow)
          warning(paste("Some rows were removed during data preparation.",
                        "Predictions will not match input dataframe."))

      }

      run_env <- new.env(parent = globalenv())
      run_env$input <- input; run_env$output <- output
      debug_flag <- isdebugged(predict_fn)
      environment(predict_fn) <<- run_env
      if (debug_flag) debug(predict_fn)

      .run_hooks('predict_post_munge')

      (if (!verbose) capture.output else function(...) eval.parent(...))(
        res <-
          if (length(formals(predict_fn)) < 2 || missing(predict_args)) {
            predict_fn(dataframe)
          } else { predict_fn(dataframe, predict_args) }
      )
      input <<- run_env$input; output <<- run_env$output
      res
    },
    
    munge = function(dataframe, steps = TRUE) {
      mungebits::munge(dataframe, munge_procedure[steps]) 
    },

    show = function() {
      cat(paste("A tundraContainer of type", sQuote(keyword)), "\n")
    },

    add_hook = function(type, hook_function) {
      stopifnot(is.character(type) && length(type) == 1)
      stopifnot(is.function(hook_function))
      allowed_types <- paste0(as.character(outer(
        c('train', 'predict'), c('pre', 'post'), paste, sep = '_')), '_munge')
      if (!is.element(type, allowed_types)) {
        stop("Tundra container hooks must be one of: ",
             paste(allowed_types, collapse = ", "))
      }

      hooks[[type]] <<- c(hooks[[type]], hook_function)
    },

    .run_hooks = function(type) {
      if (!exists('hooks')) return() # Backwards compatibility
      for (i in seq_along(hooks[[type]])) {
        eval.parent(bquote({
          `*fn*` <- hooks[[.(type)]][[.(i)]]
          environment(`*fn*`) <- environment()
          `*fn*`()
        }))
      }
    }
  )
)

#' @export
summary.tundraContainer <- function(x, ...) summary(x$output$model, ...)
#' @export
print.tundraContainer <-
  function(x, ...) print(paste("A tundraContainer of type", sQuote(x$keyword)), ...)
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>tundra_gbm.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' Tundra GBM wrapper
#
tundra_gbm_train_fn <- function(dataframe) {
  cat("Training GBM model...\n")
  suppressPackageStartupMessages(library(gbm))

  gbm_args <- list()
  indep_vars <- setdiff(colnames(dataframe), 'dep_var')
  stopifnot(length(indep_vars) > 0)
  input$debug <- isTRUE(input$debug) %||% FALSE

  if (input$cv) {
    gbm_args[[1]] <- as.formula(paste('dep_var ~ `',
                                      paste(indep_vars, collapse = "` + `"),
                                      '`', sep = ''))
    gbm_args$data <- dataframe
    gbm_args$cv.folds <- input$cv_folds
    if (identical(gbm_args$cv.folds, 1))
      stop("Using cv.folds = 1 makes GBM crash. Probably don't want that.")
    gbm_args$n.cores  <- input$number_of_cores
  } else {
    gbm_args$x <- dataframe[, indep_vars]
    gbm_args$y <- dataframe[, 'dep_var']
  }
  gbm_args <- append(gbm_args,
    list(distribution      = input$distribution,
         n.trees           = input$number_of_trees,
         shrinkage         = input$shrinkage_factor,
         interaction.depth = input$depth,
         n.minobsinnode    = input$min_observations,
         train.fraction    = input$train_fraction,
         bag.fraction      = input$bag_fraction,
         var.monotone      = input$var.monotone,
         verbose           = TRUE,
         keep.data         = if (is.null(input$keep.data)) FALSE else as.logical(input$keep.data)
    )
  )

  # Hack to prevent a hellbug where the AWS.tools package
  # masks the stopCluster function, causing a problem in gbm training
  assign('stopCluster', parallel::stopCluster, envir = globalenv())
  if (isTRUE(input$debug)) assign('gbm_args', gbm_args, envir = globalenv())
  output <<- list(model = do.call(gbm, gbm_args), perf = list())
  rm('stopCluster', envir = globalenv())

  if (!is.null(input$perf_method)) {
    output$perf[[input$perf_method]] <<-
      gbm.perf(output$model, method = input$perf_method, plot.it = FALSE)
  }
  if (!is.null(input$prediction_type))
    output$prediction_type <<- input$prediction_type

  invisible("gbm")
}

tundra_gbm_predict_fn <- function(dataframe, predict_args = list()) {
  if (is.null(input$perf_method) && is.null(predict_args$perf_method))
    stop("No GBM performance method specified: must be OOB, test, or cv") 

  require(gbm)

  type <- if (is.null(predict_args$prediction_type)) output$prediction_type
          else predict_args$prediction_type

  # Perf method specified, check if cached
  perf_method <- if (is.null(predict_args$perf_method)) input$perf_method
                 else predict_args$perf_method

  if (!perf_method %in% names(output$perf))
    output$perf[[perf_method]] <<- 
      gbm.perf(output$model, method = perf_method, plot.it = FALSE)

  predict.gbm(object = output$model, newdata = dataframe,
    output$perf[[perf_method]], type = type)
}

#' @export
tundra_gbm <- function(munge_procedure = list(), default_args = list(), internal = list()) {
  tundra:::tundra_container$new('gbm',
                       tundra_gbm_train_fn,
                       tundra_gbm_predict_fn,
                       munge_procedure,
                       default_args,
                       internal)
}
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>tundra_random_forest.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' Tundra Random Forest wrapper
#
tundra_rf_train_fn <- function(dataframe) {
  cat("Training Random Forest model...\n")
  require(party)
  require(survival)
  rf_args <- list()
  
  if(input$distribution == "coxph"){
    indep_vars <- setdiff(colnames(dataframe), c('dep_var', 'surv_time'))
  } else {
  indep_vars <- setdiff(colnames(dataframe), 'dep_var')
  }
  stopifnot(length(indep_vars) > 0)
  
  if(input$distribution == "coxph") {
    rf_args$data <- within(dataframe, surv.. <- Surv(surv_time, dep_var))
    rf_args$formula <- as.formula(paste('surv.. ~ `',
                                      paste(setdiff(indep_vars, 'surv..'), collapse = "` + `"),
                                      '`', sep = ''))
  } else {
    
    rf_args$data <- dataframe
    rf_args$formula <- as.formula(paste('dep_var ~ `',
                                      paste(indep_vars, collapse = "` + `"),
                                      '`', sep = ''))  
  }
  rf_args$controls <- cforest_unbiased(input$trees, input$branches)
  
  #set.seed(input$seed %||% 100)
  output <<- list(model = do.call(cforest, rf_args)) 
  
  if (!is.null(input$prediction_type))
    output$prediction_type <<- input$prediction_type
  invisible("random_forest")
}

tundra_rf_predict_fn <- function(dataframe, predict_args = list()) {
  if (is.null(input$OOB) && is.null(predict_args$OOB))
    stop("No Random Forest performance method specified: must specify OOB") 
  
  require(party)
  
  type <- if (is.null(predict_args$prediction_type)) output$prediction_type
  else predict_args$prediction_type
  
  # Perf method specified, check if cached
  OOB <- if (is.null(predict_args$perf_method)) input$OOB
  else predict_args$OOB
  
    preds <- predict(object = output$model, newdata = dataframe,
                     type = type, OOB = OOB)

  if(input$distribution == "coxph"){
    preds
   } else { 
    Reduce(rbind, preds)[ , grep("1$", colnames(preds[[1]]))]
  }
  #vapply(preds, function(x) x[[grep("1$", colnames(x))]], numeric(1))
}

#' @export
tundra_random_forest <- function(munge_procedure = list(), default_args = list(), internal = list() ) {
  tundra:::tundra_container$new('random_forest',
                                tundra_rf_train_fn,
                                tundra_rf_predict_fn,
                                munge_procedure,
                                default_args,
                                internal )
}
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>tundra_regularization.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' Tundra regularization wrapper
#

tundra_regularization_train_fn <- function(dataframe) {
  cat("Training Regularized Logistic Regression model...\n")
  library(glmnet)
  regularization_args <- list()
  indep_vars <- setdiff(colnames(dataframe), 'dep_var')
  stopifnot(length(indep_vars) > 0)    
  
  defaults <- list(family       ="binomial", 
                   alpha        = 0.5,
                   nfolds       = 10,
                   standardize  = FALSE, 
                   type.measure = "deviance"
                   #penalty      = 1
              )
  # alpha : 
  # The elasticnet mixing parameter, with 0<=alpha<=1. The penalty is defined as
  # (1-alpha)/[2*(beta)_2_norm^2] + alpha*beta_1_norm
  # alpha = 1   <=> Lasso penalty
  # alpha = 0.5 <=> Elastic Net penalty
  # alpha = 0   <=> Ridge penalty

  lapply(names(defaults), function(name) input[[name]] <<- input[[name]] %||% defaults[[name]])

  regularization_args$x <- model.matrix(as.formula(paste('~', paste(indep_vars, collapse='+'))),
                                        data = dataframe[, indep_vars])
  regularization_args$y <- as.matrix(dataframe[, 'dep_var'])
  regularization_args$family <- input$family
  regularization_args$alpha  <- input$alpha
  regularization_args$nfolds  <- input$nfolds
  regularization_args$standardize  <- input$standardize
  regularization_args$type.measure  <- input$type.measure

  #output <<- list(model = do.call(cv.glmnet, regularization_args), indep_vars = indep_vars)
  output <<- list(model = cv.glmnet( x = regularization_args$x, 
                        y = regularization_args$y, 
                        family = regularization_args$family, 
                        alpha = regularization_args$alpha, 
                        nfolds = regularization_args$nfolds, 
                        standardize =  regularization_args$standardize, 
                        type.measure =  regularization_args$type.measure),
                  indep_vars = indep_vars)
  if (!is.null(input$prediction_type))
    output$prediction_type <<- input$prediction_type
  
  invisible("regularization")
}

tundra_regularization_predict_fn <- function(dataframe, predict_args = list()) {
  require(glmnet)
  
  type <- if (is.null(predict_args$prediction_type)) output$prediction_type
          else predict_args$prediction_type
  
  # s specified, check if cached
  perf_method <- predict_args$penalty %||% input$penalty %||% output$model$lambda.1se
  
  predict(object = output$model$glmnet.fit,
          newx = 
            model.matrix(as.formula(paste('~', paste(output$indep_vars, collapse = '+'))),
                         dataframe[, output$indep_vars]),
          s = perf_method, type = type)[, 1]
}

#' @export
tundra_regularization <- function(munge_procedure = list(), default_args = list(), internal = list()) {
  tundra:::tundra_container$new('regularization',
                       tundra_regularization_train_fn,
                       tundra_regularization_predict_fn,
                       munge_procedure,
                       default_args,
                       internal)
}</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>tundra-package.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' tundra
#'
#' @name tundra
#' @docType package
NULL</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>utils.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">`%||%` <- function(x, y) if (is.null(x)) y else x
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>zzz.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">.onAttach <- function(...) {
  require(mungebits)
  require(syberiaMungebits)
  require(stagerunner)
}</span></code>
            </pre>
          </div>
        </div>
      <div class="section">
      </div>

    </div>
  </body>
</html>
